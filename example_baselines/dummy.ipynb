{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Original Implementation by Gyubok Lee -->\n",
        "<!-- Refined by Sunjun Kweon on 2024-01-15. -->\n",
        "<!-- Refined by Woosog Chay on 2025-02-21. -->\n",
        "<!-- Note: This Jupyter notebook is tailored to the unique requirements of the EHRSQL project. It includes specific modifications and additional adjustments to cater to the dataset and experiment objectives. -->\n",
        "\n",
        "# Dummy Model Sample Code for MIMIC-IV: Single-Turn Text-to-SQL with Abstention on Electronic Health Records\n",
        "\n",
        "\n",
        "<!-- ## Task Introduction\n",
        "The goal of the task is to **develop a reliable text-to-SQL system on EHR**. Unlike standard text-to-SQL tasks, this system must handle all types of questions, including answerable and unanswerable ones with respect to the EHR database structure. For answerable questions, the system must accurately generate SQL queries. For unanswerable questions, the system must correctly identify them as such, thereby preventing incorrect SQL predictions for infeasible questions. The range of questions includes answerable queries about MIMIC-IV, covering topics such as patient demographics, vital signs, and specific disease survival rates ([EHRSQL](https://github.com/glee4810/EHRSQL)). Additionally, there are specially designed unanswerable questions intended to challenge the system. Successfully completing this task will result in the creation of a reliable question-answering system for EHRs, significantly improving the flexibility and efficiency of clinical knowledge exploration in hospitals. -->\n",
        "\n",
        "## Steps of Baseline Code\n",
        "\n",
        "- [x] Step 1: Clone the GitHub Repository and Install Dependencies\n",
        "- [x] Step 2: Import Global Packages and Define File Paths\n",
        "- [x] Step 3: Load Data and Prepare Datasets\n",
        "- [x] Step 4: Building a Dummy Model\n",
        "- [x] Step 5: Evaluation\n"
      ],
      "metadata": {
        "id": "fV7pV4ue_8Ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Clone the GitHub Repository and Install Dependencies"
      ],
      "metadata": {
        "id": "76ZXSJhhAqZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you begin, make sure you're in the correct directory. If you need to reset the repository directory, remove the existing directory by uncommenting and executing the following lines:"
      ],
      "metadata": {
        "id": "S1hbegr4BADN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf ai612_project_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc_VUmzR_83L",
        "outputId": "475355f2-03a0-4e64-fd10-ca6c1c51bf1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, clone the repository and install the required Python packages:"
      ],
      "metadata": {
        "id": "OBpg7kpMBEHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning the GitHub repository\n",
        "!git clone -q https://github.com/benchay1999/ai612_project_1.git\n",
        "%cd ai612_project_1\n",
        "\n",
        "# Installing dependencies\n",
        "!pip install -q func_timeout"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLOhRzcCBB_d",
        "outputId": "2f23e0f5-203f-4274-81a9-1332810ed761"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ai612_project_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `%load_ext` magic command to automatically reload modules before executing a new line:"
      ],
      "metadata": {
        "id": "O5D2VbclBcJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "1ocUNohyBHUs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import Global Packages and Define File Paths\n",
        "\n",
        "After setting up the repository and dependencies, the next step is to import packages that will be used globally throughout this notebook and to define the file paths to our datasets."
      ],
      "metadata": {
        "id": "wr2zM1EVBj-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Directory paths for database, results and scoring program\n",
        "DB_ID = 'mimic_iv'\n",
        "BASE_DATA_DIR = 'data'\n",
        "RESULT_DIR = 'results'\n",
        "SCORING_DIR = 'scoring'\n",
        "\n",
        "# File paths for the dataset and labels\n",
        "TABLES_PATH = os.path.join('database', 'tables.json')               # JSON containing database schema\n",
        "VALID_DATA_PATH = os.path.join(BASE_DATA_DIR, 'valid_data.json')    # JSON file for validation data\n",
        "VALID_LABEL_PATH = os.path.join(BASE_DATA_DIR, 'valid_label.json')  # JSON file for validation labels (for evaluation)\n",
        "DB_PATH = os.path.join('data', DB_ID, f'{DB_ID}.sqlite')            # Database path\n",
        "\n",
        "# Load data\n",
        "with open(os.path.join(VALID_DATA_PATH), 'r') as f:\n",
        "    valid_data = json.load(f)\n",
        "\n",
        "with open(os.path.join(VALID_LABEL_PATH), 'r') as f:\n",
        "    valid_labels = json.load(f)\n",
        "\n",
        "# Load SQL assumptions for MIMIC-IV\n",
        "assumptions = open(\"database/mimic_iv_assumption.txt\", \"r\").read()"
      ],
      "metadata": {
        "id": "PuvpWuLRBeo3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(assumptions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qEbwPmW-SdP",
        "outputId": "60a505ca-9727-4e19-bcd0-ee1d06f1284d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Use SQLite for SQL query generation.\n",
            "- Use DENSE_RANK() when asked for ranking results, but retrieve only the relevant items, excluding their counts or ranks. When the question does not explicitly mention ranking, don't use DENSE_RANK().\n",
            "- For the top N results, return only the relevant items, excluding their counts.\n",
            "- Use DISTINCT in queries related to the cost of events, drug routes, or when counting or listing patients or hospital/ICU visits.\n",
            "- When calculating the total cost, sum the patient’s diagnoses, procedures, lab events, and prescription costs within a single hospital admission only.\n",
            "- Use DISTINCT to retrieve the cost of a single event (diagnosis, procedure, lab event, or prescription).\n",
            "- For cost-related questions, use cost.event_type to specify the event type ('procedures_icd', 'labevents', 'prescriptions', 'diagnoses_icd') when retrieving costs for procedures, lab events, prescriptions, or diagnoses, respectively.\n",
            "- Treat questions that start with \"is it possible,\" \"can you confirm,\" or \"verify\" as true/false questions.\n",
            "- Calculate a patient's age once per hospital admission. The age remains constant even if the hospital stay exceeds one year.\n",
            "- Use inputevents for input-related values and outputevents for output-related values.\n",
            "- Values are table-specific (e.g., \"propofol\" in inputevents will not appear in prescriptions).\n",
            "- When asked about the careunit, refer to the careunit information in the transfer table.\n",
            "- When asked to retrieve procedures, diagnoses, or lab tests, return their names or labels of their medical codes (i.e., procedure: d_icd_procedures.long_title, diagnosis: d_icd_diagnoses.long_title, lab test: d_labitems.label).\n",
            "- When a question involves the time of diagnosis in relation to other types of events, use the first diagnosis time for each patient.\n",
            "- When calculating the N-year survival/mortality rate:\n",
            "  - A patient is considered deceased if a death record exists between their first diagnosis and N years later.\n",
            "  - If no death record exists within N years, or if the death occurs afterward, the patient is considered to have survived.\n",
            "  - Express the result as a percentage or proportion (values between 0 and 1).\n",
            "  - \"3 months\" refers to 365/4 days, and \"6 months\" refers to 365/2 days when calculating a duration.\n",
            "- Time-related SQL operations:\n",
            "  - Use the following information for the current time instead of SQLite's native function.\n",
            "  - Use '2100-12-31 23:59:00' instead of 'now', '2100-12-31' instead of 'today', '2100-12' instead of 'this month', and '2100' instead of 'this year'.\n",
            "    - Examples:\n",
            "      - prescriptions today: datetime(prescriptions.starttime,'start of day') = datetime('2100-12-31 23:59:00','start of day','-0 day')\n",
            "      - prescriptions yesterday: datetime(prescriptions.starttime,'start of day') = datetime('2100-12-31 23:59:00','start of day','-1 day')\n",
            "  - \"this month/02\" and \"last month/02\" refer to the 2nd day of the current and previous month, respectively.\n",
            "    - Examples:\n",
            "      - outputevents on this month/02: datetime(outputevents.charttime,'start of month') = datetime('2100-12-31 23:59:00','start of month','-0 month') AND strftime('%d',outputevents.charttime) = '02'\n",
            "      - outputevents on last month/02: datetime(outputevents.charttime,'start of month') = datetime('2100-12-31 23:59:00','start of month','-1 month') AND strftime('%d',outputevents.charttime) = '02'\n",
            "  - \"11/this year\" refers to November of this year; \"11/2100\" refers to November 2100; \"12/31/this year\" refers to December 31st of this year.\n",
            "    - Examples:\n",
            "      - microbiologyevents in 11/this year: datetime(microbiologyevents.charttime,'start of year') = datetime('2100-12-31 23:59:00','start of year','-0 year') AND strftime('%m',microbiologyevents.charttime) = '11'\n",
            "      - microbiologyevents in 11/2100: strftime('%Y-%m',microbiologyevents.charttime) = '2100-11'\n",
            "      - microbiologyevents on 06/15/this year: datetime(outputevents.charttime,'start of year') = datetime('2100-12-31 23:59:00','start of year','-0 year') AND strftime('%m-%d',outputevents.charttime) = '06-15'\n",
            "  - When a question involves a time window (e.g., \"since\"):\n",
            "    - Example:\n",
            "      - outputevents since 1 year ago: datetime(outputevents.charttime) >= datetime('2100-12-31 23:59:00','-1 year')\n",
            "  - Time Comparison for Two Different Events:\n",
            "    - Examples:\n",
            "      - Same Day: datetime(T1.charttime,'start of day') = datetime(T2.starttime,'start of day')\n",
            "      - Same Month: datetime(T1.charttime,'start of month') = datetime(T2.starttime,'start of month')\n",
            "      - Same Hospital Admission: T1.hadm_id = T2.hadm_id\n",
            "  - A \"current hospital admission/visit/encounter\" refers to records where the hospital discharge time does not exist (indicating a current patient). A \"last hospital visit\" is only if the hospital discharge time is present; the first hospital visit is simply the earliest recorded visit. This rule also applies to ICU admissions and careunit transfers.\n",
            "    - Examples:\n",
            "      - current hospital admission: admissions.dischtime IS NULL\n",
            "      - last hospital admission: admissions.dischtime IS NOT NULL ORDER BY admissions.admittime DESC LIMIT 1\n",
            "      - first hospital admission: admissions.dischtime IS NOT NULL ORDER BY admissions.admittime ASC LIMIT 1\n",
            "- Value Mapping Assumptions (Case-Sensitive):\n",
            "  - Use \"temperature celsius\" for body temperature.\n",
            "  - Use \"o2 saturation pulseoxymetry\" for SaO2.\n",
            "  - Use \"heart rate\" for heart rate.\n",
            "  - Use \"respiratory rate\" for respiration rate.\n",
            "  - Use \"arterial blood pressure systolic\" for systolic blood pressure.\n",
            "  - Use \"arterial blood pressure diastolic\" for diastolic blood pressure.\n",
            "  - Use \"arterial blood pressure mean\" for mean blood pressure.\n",
            "  - Use \"daily weight\" for weight.\n",
            "  - Use \"height (cm)\" for height.\n",
            "  - Use \"m\" for male and \"f\" for female.\n",
            "  - Except for the above, use the value as it is.\n",
            "- Vital-related events are stored in chartevents, not in inputevents or outputevents. Normal ranges for vital signals are as follows:\n",
            "  - body temperature: BETWEEN 35.5 AND 38.1\n",
            "  - SaO2: BETWEEN 95.0 AND 100.0\n",
            "  - heart rate: BETWEEN 60.0 AND 100.0\n",
            "  - respiration rate: BETWEEN 12.0 AND 18.0\n",
            "  - systolic blood pressure: BETWEEN 90.0 AND 120.0\n",
            "  - diastolic blood pressure: BETWEEN 60.0 AND 90.0\n",
            "  - mean blood pressure: BETWEEN 60.0 AND 110.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load Data and Prepare Datasets\n",
        "\n",
        "Now that we have our environment and paths set up, the next step is to load the data and prepare it for our model. This involves preprocessing the MIMIC-IV database, reading the data from JSON files, splitting it into training and validation sets, and then initializing our dataset object."
      ],
      "metadata": {
        "id": "grmmBy9cOwg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Statistics"
      ],
      "metadata": {
        "id": "HUUETad0PtGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valid data:\", (len(valid_data['data']), len(valid_labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2x-VlDWPrLZ",
        "outputId": "326a53d2-2eed-4c68-b7a7-19419fa9cf3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid data: (20, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Format\n",
        "\n",
        "Before proceeding with the model, it is always a good idea to explore the dataset. This includes checking the keys in the dataset, and viewing the first few entries to understand the structure of the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "_MRV2nY_P1C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore keys and data structure\n",
        "print(valid_data.keys())\n",
        "print(valid_labels[list(valid_labels.keys())[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjG8u-kwP6kB",
        "outputId": "65ad38e2-c1fd-497a-a57a-52e3fa6b97bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['version', 'data'])\n",
            "SELECT AVG(labevents.valuenum) FROM labevents WHERE labevents.hadm_id IN ( SELECT admissions.hadm_id FROM admissions WHERE admissions.subject_id = 10021487 ) AND labevents.itemid IN ( SELECT d_labitems.itemid FROM d_labitems WHERE d_labitems.label = 'bilirubin, direct' ) AND strftime('%Y-%m',labevents.charttime) >= '2100-05' GROUP BY strftime('%Y-%m',labevents.charttime)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Building a Dummy Model"
      ],
      "metadata": {
        "id": "uFY6RgyFSVgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "\n",
        "def post_process(answer):\n",
        "    answer = answer.replace('\\n', ' ')\n",
        "    answer = re.sub('[ ]+', ' ', answer)\n",
        "    answer = answer.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
        "    return answer\n",
        "\n",
        "class Model():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate(self, input_data):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            input_data: list of python dictionaries containing 'id' and 'input'\n",
        "        Returns:\n",
        "            labels: python dictionary containing sql prediction or 'null' values associated with ids\n",
        "        \"\"\"\n",
        "        labels = {}\n",
        "\n",
        "        for sample in input_data:\n",
        "            labels[sample[\"id\"]] = \"null\"\n",
        "\n",
        "        return labels"
      ],
      "metadata": {
        "id": "oYtBKk5iSXmW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myModel = Model()\n",
        "data = valid_data[\"data\"]"
      ],
      "metadata": {
        "id": "1KF30SxDgTOJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = []\n",
        "for sample in data:\n",
        "    sample_dict = {}\n",
        "    sample_dict['id'] = sample['id']\n",
        "    sample_dict['input'] = sample['question']\n",
        "    input_data.append(sample_dict)"
      ],
      "metadata": {
        "id": "yEHYS67WGt_M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate answer(SQL)\n",
        "label_y = myModel.generate(input_data)"
      ],
      "metadata": {
        "id": "i7VkY7y1gaW7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is how the predicted labels(SQLs) look like. **This should be your submission.**"
      ],
      "metadata": {
        "id": "Tvice6Gsu-hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDiQKx4Wgb8C",
        "outputId": "72a23953-47f1-460d-f6df-06a1cae4e315"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'b9c136c1e1d19649caabdeb4': 'null',\n",
              " 'b389e224ed07b11a553f0329': 'null',\n",
              " '0845eda9197d9666e0b3a017': 'null',\n",
              " '423e62850dbf99ad88d4c834': 'null',\n",
              " 'ad08e146a6e37e3a138c8c78': 'null',\n",
              " '82fed921fe732e9851109fa0': 'null',\n",
              " 'b1f43697c74666c4701854b3': 'null',\n",
              " '9cd37fc842ad70310d54ee58': 'null',\n",
              " '0e38c978a69e475449c84fee': 'null',\n",
              " '2766c75e65819b7cf9c0fba2': 'null',\n",
              " 'f7e273153edfeb72b98bd9c7': 'null',\n",
              " '49096da9fc4db23df0c9ca94': 'null',\n",
              " 'f92a9715af7d181a656d4998': 'null',\n",
              " '61158e9ccd8015f7898cb6e8': 'null',\n",
              " 'fc9243a5cde088d80aaae29a': 'null',\n",
              " '23dd8572482a3b9ef2437c37': 'null',\n",
              " 'b3baba0d3d4a30996c8d7040': 'null',\n",
              " 'd081d7e2db7e69a70b388b51': 'null',\n",
              " 'a49efc1cdf3ebbe617aa7d26': 'null',\n",
              " '60f8d59c27fe673230ac2a83': 'null'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import write_json as write_label\n",
        "\n",
        "# Save the filtered predictions to a JSON file\n",
        "os.makedirs(RESULT_DIR, exist_ok=True)\n",
        "SCORING_OUTPUT_DIR = os.path.join(RESULT_DIR, '20240000.json') # The file to submit\n",
        "write_label(SCORING_OUTPUT_DIR, label_y)\n",
        "\n",
        "# Verify the file creation\n",
        "print(\"Listing files in RESULT_DIR:\")\n",
        "!ls {RESULT_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUMTiYl4hdt_",
        "outputId": "a3ff23a7-52cf-4145-8cef-a4f1a519adf2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files in RESULT_DIR:\n",
            "20240000.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluation\n",
        "\n",
        "You can evaluate your own valid set using the following code:\n",
        "\n",
        "*Note*: The risk for questions that are not answerable is None here since there are no such data in the valid set."
      ],
      "metadata": {
        "id": "nJT6jj7WiAkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scoring.scorer import Scorer\n",
        "with open(\"data/valid_data.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "with open(\"data/valid_label.json\", \"r\") as f:\n",
        "    gold_labels = json.load(f)\n",
        "\n",
        "with open(\"results/20240000.json\", \"r\") as f:\n",
        "    predictions = json.load(f)\n",
        "scorer = Scorer(\n",
        "    data=data,\n",
        "    predictions=predictions,\n",
        "    gold_labels=valid_labels,\n",
        "    score_dir=\"results\"\n",
        ")\n",
        "print()\n",
        "print(scorer.get_scores())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1NU-hSiAUMo",
        "outputId": "e0fd4a35-cfde-4168-bf0c-bd56e2122bc1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 261.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for risk_notans. This happens when there is no `notans` questions in the evaluation dataset. This metric will be ignored when calculating the final score. This will not happen when evaluating on the test set.\n",
            "====================================================================================================\n",
            "Coverage for answerable questions (in %): 0.0 || 0/20\n",
            "Risk for answerable questions (in %): 0.0 || 0/20\n",
            "Risk for unanswerable questions (in %): None || 0/0\n",
            "Final score: 50.0\n",
            "====================================================================================================\n",
            "{'cov_ans*100': 0.0, 'risk_ans*100': 0.0, 'risk_notans*100': None, 'final_score': 50.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}